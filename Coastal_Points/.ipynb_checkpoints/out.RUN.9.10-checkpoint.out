2020-11-09 20:41:28.849345: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-11-09 20:41:28.856905: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2020-11-09 20:41:28.857079: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f21c79e2e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-09 20:41:28.857101: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-09 20:41:28.858724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-11-09 20:41:28.958591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 20:41:28.976842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 20:41:29.045995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 20:41:29.114390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 20:41:29.169399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 20:41:29.225320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 20:41:29.263914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 20:41:29.293610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 20:41:29.296895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 20:41:29.296975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 20:41:29.491231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-09 20:41:29.491299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-11-09 20:41:29.491314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-11-09 20:41:29.497109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 30591 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
2020-11-09 20:41:29.499354: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f21d5198a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-11-09 20:41:29.499394: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-11-09 20:41:29.501953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 20:41:29.502034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 20:41:29.502054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 20:41:29.502069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 20:41:29.506239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 20:41:29.506260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 20:41:29.506276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 20:41:29.506293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 20:41:29.509370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 20:41:29.509413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-09 20:41:29.509424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-11-09 20:41:29.509434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-11-09 20:41:29.512509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 30591 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
2020-11-09 20:41:29.515163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 20:41:29.515235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 20:41:29.515254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 20:41:29.515270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 20:41:29.515285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 20:41:29.515300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 20:41:29.515316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 20:41:29.515331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 20:41:29.519093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 20:41:29.519132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-09 20:41:29.519142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-11-09 20:41:29.519152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-11-09 20:41:29.522187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 30591 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
#############################################
post processing forecast: F048
#############################################
['/device:GPU:0']
#################################################
#################################################
SUCCESS: Found GPU: /device:GPU:0
#################################################
#################################################
We are here: /glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal
...Searching...: /glade/scratch/wchapman/AnEnCNN_good/Data/WestCoast/
/glade/scratch/wchapman/Reforecast/F000
/glade/scratch/wchapman/Reforecast/F006
/glade/scratch/wchapman/Reforecast/F012
/glade/scratch/wchapman/Reforecast/F018
/glade/scratch/wchapman/Reforecast/F024
/glade/scratch/wchapman/Reforecast/F030
/glade/scratch/wchapman/Reforecast/F036
/glade/scratch/wchapman/Reforecast/F042
/glade/scratch/wchapman/Reforecast/F048
Training on
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1985_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1986_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1987_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1988_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1989_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1990_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1991_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1992_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1993_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1994_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1995_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1996_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1997_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1998_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1999_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2000_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2001_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2002_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2003_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2005_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc
Validating on
/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc
Testing on
/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc
['2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']
trainging yearss ['/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc']
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc"...


Mean and standard deviation for "IVT" = 159.5592, 152.5859
Mean and standard deviation for "p_sfc" = 984.2679, 61.9675
Mean and standard deviation for "u_tr_p" = 12.5324, 12.4154
Mean and standard deviation for "v_tr_p" = 1.2532, 13.3453
Mean and standard deviation for "Z_p" = 5576.5365, 202.2918
Mean and standard deviation for "IWV" = 13.4717, 7.7792
2020-11-09 20:41:36.239602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 20:41:36.240439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 20:41:36.240465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 20:41:36.240481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 20:41:36.240496: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 20:41:36.240511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 20:41:36.240527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 20:41:36.240542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 20:41:36.247576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 20:41:36.253428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 20:41:36.253508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 20:41:36.253527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 20:41:36.253543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 20:41:36.253564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 20:41:36.253580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 20:41:36.253595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 20:41:36.253610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 20:41:36.257384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 20:41:36.257444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-09 20:41:36.257457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-11-09 20:41:36.257466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-11-09 20:41:36.260605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30591 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
2020-11-09 20:41:38.144794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 20:41:39.374453: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-11-09 20:41:39.390021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc"...


Mean and standard deviation for "IVTm" = 204.9801, 181.2149
#################################################
testing: ['/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc']
validatiing: ['/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc']
#################################################
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc"...
...gathering data...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc"...
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d (ZeroPadding2D)  (None, 72, 60, 6)    0           input_1[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d[0][0]             
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d[0][0]              
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add (Add)                       (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add[0][0]                        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate[0][0]                
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d (Cropping2D)         (None, 71, 57, 2)    0           linear[0][0]                     
==================================================================================================
Total params: 35,506
Trainable params: 35,442
Non-trainable params: 64
__________________________________________________________________________________________________
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017
....saving.... /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
....saving.... /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
Train on 1091 samples, validate on 121 samples
Epoch 1/50
  50/1091 [>.............................] - ETA: 53s - loss: 157.3126 250/1091 [=====>........................] - ETA: 8s - loss: 154.9701  450/1091 [===========>..................] - ETA: 3s - loss: 151.7684 650/1091 [================>.............] - ETA: 1s - loss: 146.8786 850/1091 [======================>.......] - ETA: 0s - loss: 132.88061050/1091 [===========================>..] - ETA: 0s - loss: 119.4215
Epoch 00001: val_loss improved from inf to 52.96344, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 3s 3ms/sample - loss: 116.9410 - val_loss: 52.9634
Epoch 2/50
  50/1091 [>.............................] - ETA: 0s - loss: 45.0570 250/1091 [=====>........................] - ETA: 0s - loss: 43.3777 450/1091 [===========>..................] - ETA: 0s - loss: 46.0137 650/1091 [================>.............] - ETA: 0s - loss: 44.2451 850/1091 [======================>.......] - ETA: 0s - loss: 43.80001050/1091 [===========================>..] - ETA: 0s - loss: 42.7978
Epoch 00002: val_loss did not improve from 52.96344
1091/1091 [==============================] - 0s 303us/sample - loss: 42.6099 - val_loss: 64.2820
Epoch 3/50
  50/1091 [>.............................] - ETA: 0s - loss: 39.1289 250/1091 [=====>........................] - ETA: 0s - loss: 36.6975 450/1091 [===========>..................] - ETA: 0s - loss: 36.7253 650/1091 [================>.............] - ETA: 0s - loss: 36.1196 850/1091 [======================>.......] - ETA: 0s - loss: 35.38791050/1091 [===========================>..] - ETA: 0s - loss: 34.8537
Epoch 00003: val_loss did not improve from 52.96344

Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.
1091/1091 [==============================] - 0s 293us/sample - loss: 34.7604 - val_loss: 60.1483
Epoch 4/50
  50/1091 [>.............................] - ETA: 0s - loss: 30.9221 250/1091 [=====>........................] - ETA: 0s - loss: 30.3463 450/1091 [===========>..................] - ETA: 0s - loss: 30.8259 650/1091 [================>.............] - ETA: 0s - loss: 30.5579 850/1091 [======================>.......] - ETA: 0s - loss: 30.53331050/1091 [===========================>..] - ETA: 0s - loss: 30.6824
Epoch 00004: val_loss did not improve from 52.96344
1091/1091 [==============================] - 0s 299us/sample - loss: 30.7323 - val_loss: 55.1196
Epoch 5/50
  50/1091 [>.............................] - ETA: 0s - loss: 29.9111 250/1091 [=====>........................] - ETA: 0s - loss: 30.2963 450/1091 [===========>..................] - ETA: 0s - loss: 30.0141 650/1091 [================>.............] - ETA: 0s - loss: 29.9886 850/1091 [======================>.......] - ETA: 0s - loss: 29.59581050/1091 [===========================>..] - ETA: 0s - loss: 29.6300
Epoch 00005: val_loss improved from 52.96344 to 49.92042, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 329us/sample - loss: 29.6867 - val_loss: 49.9204
Epoch 6/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.9502 250/1091 [=====>........................] - ETA: 0s - loss: 29.1741 450/1091 [===========>..................] - ETA: 0s - loss: 29.2412 650/1091 [================>.............] - ETA: 0s - loss: 29.1518 850/1091 [======================>.......] - ETA: 0s - loss: 28.90071050/1091 [===========================>..] - ETA: 0s - loss: 28.8071
Epoch 00006: val_loss improved from 49.92042 to 45.74479, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 323us/sample - loss: 28.7887 - val_loss: 45.7448
Epoch 7/50
  50/1091 [>.............................] - ETA: 0s - loss: 27.4291 250/1091 [=====>........................] - ETA: 0s - loss: 28.9480 450/1091 [===========>..................] - ETA: 0s - loss: 28.8075 650/1091 [================>.............] - ETA: 0s - loss: 28.7772 850/1091 [======================>.......] - ETA: 0s - loss: 28.41711050/1091 [===========================>..] - ETA: 0s - loss: 28.2362
Epoch 00007: val_loss improved from 45.74479 to 41.37122, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 328us/sample - loss: 28.2066 - val_loss: 41.3712
Epoch 8/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.2407 250/1091 [=====>........................] - ETA: 0s - loss: 28.6128 450/1091 [===========>..................] - ETA: 0s - loss: 28.4516 650/1091 [================>.............] - ETA: 0s - loss: 28.5035 850/1091 [======================>.......] - ETA: 0s - loss: 28.32521050/1091 [===========================>..] - ETA: 0s - loss: 28.1062
Epoch 00008: val_loss improved from 41.37122 to 37.82041, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 320us/sample - loss: 28.0318 - val_loss: 37.8204
Epoch 9/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.1525 250/1091 [=====>........................] - ETA: 0s - loss: 27.5139 450/1091 [===========>..................] - ETA: 0s - loss: 27.5063 650/1091 [================>.............] - ETA: 0s - loss: 27.7124 850/1091 [======================>.......] - ETA: 0s - loss: 27.61191050/1091 [===========================>..] - ETA: 0s - loss: 27.5507
Epoch 00009: val_loss improved from 37.82041 to 33.08310, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 322us/sample - loss: 27.5864 - val_loss: 33.0831
Epoch 10/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.7750 250/1091 [=====>........................] - ETA: 0s - loss: 26.8710 450/1091 [===========>..................] - ETA: 0s - loss: 26.8343 650/1091 [================>.............] - ETA: 0s - loss: 26.8974 850/1091 [======================>.......] - ETA: 0s - loss: 27.19631050/1091 [===========================>..] - ETA: 0s - loss: 27.2511
Epoch 00010: val_loss improved from 33.08310 to 31.02617, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 328us/sample - loss: 27.2448 - val_loss: 31.0262
Epoch 11/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.4529 250/1091 [=====>........................] - ETA: 0s - loss: 28.8303 450/1091 [===========>..................] - ETA: 0s - loss: 27.9619 650/1091 [================>.............] - ETA: 0s - loss: 27.6263 850/1091 [======================>.......] - ETA: 0s - loss: 27.49441050/1091 [===========================>..] - ETA: 0s - loss: 27.2212
Epoch 00011: val_loss improved from 31.02617 to 30.99653, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 324us/sample - loss: 27.1332 - val_loss: 30.9965
Epoch 12/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.6243 250/1091 [=====>........................] - ETA: 0s - loss: 27.0563 450/1091 [===========>..................] - ETA: 0s - loss: 26.8151 650/1091 [================>.............] - ETA: 0s - loss: 26.5394 850/1091 [======================>.......] - ETA: 0s - loss: 27.15021050/1091 [===========================>..] - ETA: 0s - loss: 27.1292
Epoch 00012: val_loss improved from 30.99653 to 27.69759, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 336us/sample - loss: 27.1208 - val_loss: 27.6976
Epoch 13/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.5197 250/1091 [=====>........................] - ETA: 0s - loss: 27.2840 450/1091 [===========>..................] - ETA: 0s - loss: 26.9925 650/1091 [================>.............] - ETA: 0s - loss: 27.1391 850/1091 [======================>.......] - ETA: 0s - loss: 27.05141050/1091 [===========================>..] - ETA: 0s - loss: 26.7848
Epoch 00013: val_loss did not improve from 27.69759
1091/1091 [==============================] - 0s 295us/sample - loss: 26.8058 - val_loss: 28.1293
Epoch 14/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.8096 250/1091 [=====>........................] - ETA: 0s - loss: 27.1162 450/1091 [===========>..................] - ETA: 0s - loss: 26.8478 650/1091 [================>.............] - ETA: 0s - loss: 26.8883 850/1091 [======================>.......] - ETA: 0s - loss: 26.72631050/1091 [===========================>..] - ETA: 0s - loss: 26.6987
Epoch 00014: val_loss improved from 27.69759 to 26.07451, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 328us/sample - loss: 26.6891 - val_loss: 26.0745
Epoch 15/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.2309 250/1091 [=====>........................] - ETA: 0s - loss: 26.6175 450/1091 [===========>..................] - ETA: 0s - loss: 26.4984 650/1091 [================>.............] - ETA: 0s - loss: 26.8422 850/1091 [======================>.......] - ETA: 0s - loss: 26.73601050/1091 [===========================>..] - ETA: 0s - loss: 26.6654
Epoch 00015: val_loss improved from 26.07451 to 26.03121, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 325us/sample - loss: 26.6389 - val_loss: 26.0312
Epoch 16/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.1227 150/1091 [===>..........................] - ETA: 0s - loss: 26.5840 300/1091 [=======>......................] - ETA: 0s - loss: 26.6738 500/1091 [============>.................] - ETA: 0s - loss: 26.5498 700/1091 [==================>...........] - ETA: 0s - loss: 26.3809 900/1091 [=======================>......] - ETA: 0s - loss: 26.3013
Epoch 00016: val_loss improved from 26.03121 to 25.34000, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 358us/sample - loss: 26.4536 - val_loss: 25.3400
Epoch 17/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.4327 250/1091 [=====>........................] - ETA: 0s - loss: 26.3055 450/1091 [===========>..................] - ETA: 0s - loss: 26.1880 650/1091 [================>.............] - ETA: 0s - loss: 26.2220 850/1091 [======================>.......] - ETA: 0s - loss: 26.20291050/1091 [===========================>..] - ETA: 0s - loss: 26.1779
Epoch 00017: val_loss improved from 25.34000 to 25.06000, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 319us/sample - loss: 26.1708 - val_loss: 25.0600
Epoch 18/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.0829 250/1091 [=====>........................] - ETA: 0s - loss: 26.5045 450/1091 [===========>..................] - ETA: 0s - loss: 26.5751 650/1091 [================>.............] - ETA: 0s - loss: 26.5000 850/1091 [======================>.......] - ETA: 0s - loss: 26.33551050/1091 [===========================>..] - ETA: 0s - loss: 26.2184
Epoch 00018: val_loss improved from 25.06000 to 24.84917, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 328us/sample - loss: 26.1909 - val_loss: 24.8492
Epoch 19/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.0492 250/1091 [=====>........................] - ETA: 0s - loss: 26.1938 450/1091 [===========>..................] - ETA: 0s - loss: 26.3268 650/1091 [================>.............] - ETA: 0s - loss: 26.1852 850/1091 [======================>.......] - ETA: 0s - loss: 26.17481050/1091 [===========================>..] - ETA: 0s - loss: 26.0427
Epoch 00019: val_loss did not improve from 24.84917
1091/1091 [==============================] - 0s 294us/sample - loss: 26.0450 - val_loss: 24.9262
Epoch 20/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.3101 250/1091 [=====>........................] - ETA: 0s - loss: 27.1015 450/1091 [===========>..................] - ETA: 0s - loss: 26.4152 650/1091 [================>.............] - ETA: 0s - loss: 26.2547 850/1091 [======================>.......] - ETA: 0s - loss: 26.22981050/1091 [===========================>..] - ETA: 0s - loss: 26.3079
Epoch 00020: val_loss improved from 24.84917 to 24.36749, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 329us/sample - loss: 26.2845 - val_loss: 24.3675
Epoch 21/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.1495 250/1091 [=====>........................] - ETA: 0s - loss: 25.9860 450/1091 [===========>..................] - ETA: 0s - loss: 25.7885 650/1091 [================>.............] - ETA: 0s - loss: 25.9528 850/1091 [======================>.......] - ETA: 0s - loss: 26.08031050/1091 [===========================>..] - ETA: 0s - loss: 26.0652
Epoch 00021: val_loss did not improve from 24.36749
1091/1091 [==============================] - 0s 298us/sample - loss: 26.0536 - val_loss: 24.8361
Epoch 22/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.6847 250/1091 [=====>........................] - ETA: 0s - loss: 26.0758 450/1091 [===========>..................] - ETA: 0s - loss: 26.1228 650/1091 [================>.............] - ETA: 0s - loss: 25.8425 850/1091 [======================>.......] - ETA: 0s - loss: 25.87111050/1091 [===========================>..] - ETA: 0s - loss: 25.7916
Epoch 00022: val_loss did not improve from 24.36749

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.
1091/1091 [==============================] - 0s 298us/sample - loss: 25.7766 - val_loss: 24.6192
Epoch 23/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.9825 250/1091 [=====>........................] - ETA: 0s - loss: 26.0285 450/1091 [===========>..................] - ETA: 0s - loss: 26.3839 650/1091 [================>.............] - ETA: 0s - loss: 26.1881 850/1091 [======================>.......] - ETA: 0s - loss: 25.93371050/1091 [===========================>..] - ETA: 0s - loss: 25.7207
Epoch 00023: val_loss did not improve from 24.36749
1091/1091 [==============================] - 0s 297us/sample - loss: 25.7132 - val_loss: 24.8299
Epoch 24/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.2092 250/1091 [=====>........................] - ETA: 0s - loss: 25.7983 450/1091 [===========>..................] - ETA: 0s - loss: 25.6206 650/1091 [================>.............] - ETA: 0s - loss: 25.6274 850/1091 [======================>.......] - ETA: 0s - loss: 25.70031050/1091 [===========================>..] - ETA: 0s - loss: 25.7643
Epoch 00024: val_loss improved from 24.36749 to 24.16168, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 320us/sample - loss: 25.7691 - val_loss: 24.1617
Epoch 25/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.4854 250/1091 [=====>........................] - ETA: 0s - loss: 25.6641 450/1091 [===========>..................] - ETA: 0s - loss: 25.6962 650/1091 [================>.............] - ETA: 0s - loss: 26.0163 850/1091 [======================>.......] - ETA: 0s - loss: 26.00281050/1091 [===========================>..] - ETA: 0s - loss: 25.8697
Epoch 00025: val_loss did not improve from 24.16168
1091/1091 [==============================] - 0s 297us/sample - loss: 25.8142 - val_loss: 24.2356
Epoch 26/50
  50/1091 [>.............................] - ETA: 0s - loss: 24.6113 250/1091 [=====>........................] - ETA: 0s - loss: 25.8266 450/1091 [===========>..................] - ETA: 0s - loss: 26.0475 650/1091 [================>.............] - ETA: 0s - loss: 25.7248 850/1091 [======================>.......] - ETA: 0s - loss: 25.59821050/1091 [===========================>..] - ETA: 0s - loss: 25.4892
Epoch 00026: val_loss improved from 24.16168 to 24.15045, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 327us/sample - loss: 25.5585 - val_loss: 24.1504
Epoch 27/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.2140 250/1091 [=====>........................] - ETA: 0s - loss: 25.8949 450/1091 [===========>..................] - ETA: 0s - loss: 25.2027 650/1091 [================>.............] - ETA: 0s - loss: 25.1080 850/1091 [======================>.......] - ETA: 0s - loss: 25.33671050/1091 [===========================>..] - ETA: 0s - loss: 25.4647
Epoch 00027: val_loss improved from 24.15045 to 23.95396, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 324us/sample - loss: 25.4869 - val_loss: 23.9540
Epoch 28/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.9103 250/1091 [=====>........................] - ETA: 0s - loss: 25.7264 450/1091 [===========>..................] - ETA: 0s - loss: 25.3776 650/1091 [================>.............] - ETA: 0s - loss: 25.4346 850/1091 [======================>.......] - ETA: 0s - loss: 25.62421050/1091 [===========================>..] - ETA: 0s - loss: 25.6531
Epoch 00028: val_loss did not improve from 23.95396
1091/1091 [==============================] - 0s 300us/sample - loss: 25.6603 - val_loss: 23.9893
Epoch 29/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.6552 250/1091 [=====>........................] - ETA: 0s - loss: 25.8682 450/1091 [===========>..................] - ETA: 0s - loss: 25.8661 650/1091 [================>.............] - ETA: 0s - loss: 25.7469 850/1091 [======================>.......] - ETA: 0s - loss: 25.57641050/1091 [===========================>..] - ETA: 0s - loss: 25.4320
Epoch 00029: val_loss did not improve from 23.95396

Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.
1091/1091 [==============================] - 0s 299us/sample - loss: 25.5501 - val_loss: 23.9584
Epoch 30/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.6467 250/1091 [=====>........................] - ETA: 0s - loss: 25.9692 450/1091 [===========>..................] - ETA: 0s - loss: 25.9195 650/1091 [================>.............] - ETA: 0s - loss: 25.6903 850/1091 [======================>.......] - ETA: 0s - loss: 25.47871050/1091 [===========================>..] - ETA: 0s - loss: 25.5756
Epoch 00030: val_loss improved from 23.95396 to 23.82924, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 317us/sample - loss: 25.5395 - val_loss: 23.8292
Epoch 31/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.7308 250/1091 [=====>........................] - ETA: 0s - loss: 25.9624 450/1091 [===========>..................] - ETA: 0s - loss: 25.8888 650/1091 [================>.............] - ETA: 0s - loss: 25.6208 850/1091 [======================>.......] - ETA: 0s - loss: 25.54231050/1091 [===========================>..] - ETA: 0s - loss: 25.3791
Epoch 00031: val_loss improved from 23.82924 to 23.82662, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 324us/sample - loss: 25.3945 - val_loss: 23.8266
Epoch 32/50
  50/1091 [>.............................] - ETA: 0s - loss: 23.8428 250/1091 [=====>........................] - ETA: 0s - loss: 25.1523 450/1091 [===========>..................] - ETA: 0s - loss: 25.1742 650/1091 [================>.............] - ETA: 0s - loss: 25.2911 850/1091 [======================>.......] - ETA: 0s - loss: 25.32101050/1091 [===========================>..] - ETA: 0s - loss: 25.2910
Epoch 00032: val_loss improved from 23.82662 to 23.80010, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 323us/sample - loss: 25.3722 - val_loss: 23.8001
Epoch 33/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.3919 250/1091 [=====>........................] - ETA: 0s - loss: 25.3269 450/1091 [===========>..................] - ETA: 0s - loss: 25.1226 650/1091 [================>.............] - ETA: 0s - loss: 25.2235 850/1091 [======================>.......] - ETA: 0s - loss: 25.35741050/1091 [===========================>..] - ETA: 0s - loss: 25.3938
Epoch 00033: val_loss did not improve from 23.80010
1091/1091 [==============================] - 0s 293us/sample - loss: 25.4290 - val_loss: 23.8288
Epoch 34/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.3003 250/1091 [=====>........................] - ETA: 0s - loss: 25.3127 450/1091 [===========>..................] - ETA: 0s - loss: 25.5533 650/1091 [================>.............] - ETA: 0s - loss: 25.4552 850/1091 [======================>.......] - ETA: 0s - loss: 25.39561050/1091 [===========================>..] - ETA: 0s - loss: 25.4107
Epoch 00034: val_loss did not improve from 23.80010

Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.
1091/1091 [==============================] - 0s 291us/sample - loss: 25.4181 - val_loss: 23.8002
Epoch 35/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.0406 250/1091 [=====>........................] - ETA: 0s - loss: 25.2911 450/1091 [===========>..................] - ETA: 0s - loss: 25.4735 650/1091 [================>.............] - ETA: 0s - loss: 25.4948 850/1091 [======================>.......] - ETA: 0s - loss: 25.45481050/1091 [===========================>..] - ETA: 0s - loss: 25.3661
Epoch 00035: val_loss improved from 23.80010 to 23.78340, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 327us/sample - loss: 25.3522 - val_loss: 23.7834
Epoch 36/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.9060 250/1091 [=====>........................] - ETA: 0s - loss: 25.1197 450/1091 [===========>..................] - ETA: 0s - loss: 25.2850 650/1091 [================>.............] - ETA: 0s - loss: 25.6525 850/1091 [======================>.......] - ETA: 0s - loss: 25.59111050/1091 [===========================>..] - ETA: 0s - loss: 25.4240
Epoch 00036: val_loss improved from 23.78340 to 23.77582, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 318us/sample - loss: 25.3828 - val_loss: 23.7758
Epoch 37/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.5820 250/1091 [=====>........................] - ETA: 0s - loss: 25.1688 450/1091 [===========>..................] - ETA: 0s - loss: 25.4530 650/1091 [================>.............] - ETA: 0s - loss: 25.3820 850/1091 [======================>.......] - ETA: 0s - loss: 25.37711050/1091 [===========================>..] - ETA: 0s - loss: 25.3181
Epoch 00037: val_loss did not improve from 23.77582
1091/1091 [==============================] - 0s 295us/sample - loss: 25.3539 - val_loss: 23.7783
Epoch 38/50
  50/1091 [>.............................] - ETA: 0s - loss: 24.6510 250/1091 [=====>........................] - ETA: 0s - loss: 25.8198 450/1091 [===========>..................] - ETA: 0s - loss: 25.3858 650/1091 [================>.............] - ETA: 0s - loss: 25.4077 850/1091 [======================>.......] - ETA: 0s - loss: 25.28901050/1091 [===========================>..] - ETA: 0s - loss: 25.3745
Epoch 00038: val_loss improved from 23.77582 to 23.76764, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 328us/sample - loss: 25.3412 - val_loss: 23.7676
Epoch 39/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.2290 250/1091 [=====>........................] - ETA: 0s - loss: 25.6213 450/1091 [===========>..................] - ETA: 0s - loss: 25.6279 650/1091 [================>.............] - ETA: 0s - loss: 25.5056 850/1091 [======================>.......] - ETA: 0s - loss: 25.33341050/1091 [===========================>..] - ETA: 0s - loss: 25.3877
Epoch 00039: val_loss improved from 23.76764 to 23.75982, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 323us/sample - loss: 25.3913 - val_loss: 23.7598
Epoch 40/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.2430 250/1091 [=====>........................] - ETA: 0s - loss: 25.5695 450/1091 [===========>..................] - ETA: 0s - loss: 25.3698 650/1091 [================>.............] - ETA: 0s - loss: 25.2817 850/1091 [======================>.......] - ETA: 0s - loss: 25.34381050/1091 [===========================>..] - ETA: 0s - loss: 25.3537
Epoch 00040: val_loss improved from 23.75982 to 23.75584, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 324us/sample - loss: 25.3650 - val_loss: 23.7558
Epoch 41/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.3415 250/1091 [=====>........................] - ETA: 0s - loss: 26.0507 450/1091 [===========>..................] - ETA: 0s - loss: 25.6327 650/1091 [================>.............] - ETA: 0s - loss: 25.5546 850/1091 [======================>.......] - ETA: 0s - loss: 25.36751050/1091 [===========================>..] - ETA: 0s - loss: 25.3416
Epoch 00041: val_loss did not improve from 23.75584
1091/1091 [==============================] - 0s 298us/sample - loss: 25.4034 - val_loss: 23.7561
Epoch 42/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.4363 250/1091 [=====>........................] - ETA: 0s - loss: 26.0035 450/1091 [===========>..................] - ETA: 0s - loss: 25.8248 650/1091 [================>.............] - ETA: 0s - loss: 25.7718 850/1091 [======================>.......] - ETA: 0s - loss: 25.42031050/1091 [===========================>..] - ETA: 0s - loss: 25.3452
Epoch 00042: val_loss improved from 23.75584 to 23.75165, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 321us/sample - loss: 25.3771 - val_loss: 23.7517
Epoch 43/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.0445 250/1091 [=====>........................] - ETA: 0s - loss: 25.6422 450/1091 [===========>..................] - ETA: 0s - loss: 25.2792 650/1091 [================>.............] - ETA: 0s - loss: 25.3831 850/1091 [======================>.......] - ETA: 0s - loss: 25.47431050/1091 [===========================>..] - ETA: 0s - loss: 25.4171
Epoch 00043: val_loss improved from 23.75165 to 23.74376, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 321us/sample - loss: 25.4439 - val_loss: 23.7438
Epoch 44/50
  50/1091 [>.............................] - ETA: 0s - loss: 23.8672 250/1091 [=====>........................] - ETA: 0s - loss: 25.0802 450/1091 [===========>..................] - ETA: 0s - loss: 24.9532 650/1091 [================>.............] - ETA: 0s - loss: 25.1792 850/1091 [======================>.......] - ETA: 0s - loss: 25.55361050/1091 [===========================>..] - ETA: 0s - loss: 25.4971
Epoch 00044: val_loss did not improve from 23.74376
1091/1091 [==============================] - 0s 305us/sample - loss: 25.5000 - val_loss: 23.7459
Epoch 45/50
  50/1091 [>.............................] - ETA: 0s - loss: 24.6465 250/1091 [=====>........................] - ETA: 0s - loss: 25.4398 450/1091 [===========>..................] - ETA: 0s - loss: 25.2547 650/1091 [================>.............] - ETA: 0s - loss: 25.1861 850/1091 [======================>.......] - ETA: 0s - loss: 25.27141050/1091 [===========================>..] - ETA: 0s - loss: 25.3015
Epoch 00045: val_loss improved from 23.74376 to 23.73871, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 320us/sample - loss: 25.2984 - val_loss: 23.7387
Epoch 46/50
  50/1091 [>.............................] - ETA: 0s - loss: 24.3639 250/1091 [=====>........................] - ETA: 0s - loss: 25.8619 450/1091 [===========>..................] - ETA: 0s - loss: 25.5629 650/1091 [================>.............] - ETA: 0s - loss: 25.3239 850/1091 [======================>.......] - ETA: 0s - loss: 25.43881050/1091 [===========================>..] - ETA: 0s - loss: 25.4706
Epoch 00046: val_loss did not improve from 23.73871
1091/1091 [==============================] - 0s 291us/sample - loss: 25.4491 - val_loss: 23.7388
Epoch 47/50
  50/1091 [>.............................] - ETA: 0s - loss: 24.8127 250/1091 [=====>........................] - ETA: 0s - loss: 24.7032 450/1091 [===========>..................] - ETA: 0s - loss: 25.5186 650/1091 [================>.............] - ETA: 0s - loss: 25.4189 850/1091 [======================>.......] - ETA: 0s - loss: 25.39801050/1091 [===========================>..] - ETA: 0s - loss: 25.4143
Epoch 00047: val_loss improved from 23.73871 to 23.73333, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 322us/sample - loss: 25.3924 - val_loss: 23.7333
Epoch 48/50
  50/1091 [>.............................] - ETA: 0s - loss: 23.8665 250/1091 [=====>........................] - ETA: 0s - loss: 26.3266 350/1091 [========>.....................] - ETA: 0s - loss: 26.4610 550/1091 [==============>...............] - ETA: 0s - loss: 25.9644 750/1091 [===================>..........] - ETA: 0s - loss: 25.7985 950/1091 [=========================>....] - ETA: 0s - loss: 25.6059
Epoch 00048: val_loss improved from 23.73333 to 23.73167, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 363us/sample - loss: 25.5369 - val_loss: 23.7317
Epoch 49/50
  50/1091 [>.............................] - ETA: 0s - loss: 24.9122 250/1091 [=====>........................] - ETA: 0s - loss: 24.6779 450/1091 [===========>..................] - ETA: 0s - loss: 25.3841 650/1091 [================>.............] - ETA: 0s - loss: 25.6069 850/1091 [======================>.......] - ETA: 0s - loss: 25.42581050/1091 [===========================>..] - ETA: 0s - loss: 25.3245
Epoch 00049: val_loss improved from 23.73167 to 23.73093, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 327us/sample - loss: 25.4412 - val_loss: 23.7309
Epoch 50/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.4598 250/1091 [=====>........................] - ETA: 0s - loss: 25.9228 450/1091 [===========>..................] - ETA: 0s - loss: 25.5664 650/1091 [================>.............] - ETA: 0s - loss: 25.5663 850/1091 [======================>.......] - ETA: 0s - loss: 25.46151050/1091 [===========================>..] - ETA: 0s - loss: 25.4307
Epoch 00050: val_loss improved from 23.73093 to 23.72610, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
1091/1091 [==============================] - 0s 325us/sample - loss: 25.4498 - val_loss: 23.7261
#################################################
testing: ['/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc']
validatiing: ['/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc']
#################################################
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc"...
...gathering data...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc"...
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 72, 60, 6)    0           input_2[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add_1 (Add)                     (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add_1[0][0]                      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate_1[0][0]              
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 71, 57, 2)    0           linear[0][0]                     
==================================================================================================
Total params: 35,506
Trainable params: 35,442
Non-trainable params: 64
__________________________________________________________________________________________________
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018
....saving.... /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
....saving.... /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
Train on 1091 samples, validate on 121 samples
Epoch 1/50
  50/1091 [>.............................] - ETA: 15s - loss: 167.5533 150/1091 [===>..........................] - ETA: 5s - loss: 157.3912  350/1091 [========>.....................] - ETA: 1s - loss: 157.4520 550/1091 [==============>...............] - ETA: 0s - loss: 156.1501 750/1091 [===================>..........] - ETA: 0s - loss: 151.4711 950/1091 [=========================>....] - ETA: 0s - loss: 139.4669
Epoch 00001: val_loss improved from inf to 60.91054, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 2s 1ms/sample - loss: 128.2031 - val_loss: 60.9105
Epoch 2/50
  50/1091 [>.............................] - ETA: 0s - loss: 53.3374 250/1091 [=====>........................] - ETA: 0s - loss: 54.2134 450/1091 [===========>..................] - ETA: 0s - loss: 49.4995 650/1091 [================>.............] - ETA: 0s - loss: 48.4929 850/1091 [======================>.......] - ETA: 0s - loss: 46.22831050/1091 [===========================>..] - ETA: 0s - loss: 44.8498
Epoch 00002: val_loss did not improve from 60.91054
1091/1091 [==============================] - 0s 299us/sample - loss: 44.6354 - val_loss: 74.5665
Epoch 3/50
  50/1091 [>.............................] - ETA: 0s - loss: 38.2404 250/1091 [=====>........................] - ETA: 0s - loss: 36.0680 450/1091 [===========>..................] - ETA: 0s - loss: 35.7554 650/1091 [================>.............] - ETA: 0s - loss: 35.3553 850/1091 [======================>.......] - ETA: 0s - loss: 35.23991050/1091 [===========================>..] - ETA: 0s - loss: 34.9571
Epoch 00003: val_loss did not improve from 60.91054

Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.
1091/1091 [==============================] - 0s 296us/sample - loss: 34.8636 - val_loss: 72.6019
Epoch 4/50
  50/1091 [>.............................] - ETA: 0s - loss: 31.8165 250/1091 [=====>........................] - ETA: 0s - loss: 31.6108 450/1091 [===========>..................] - ETA: 0s - loss: 31.7559 650/1091 [================>.............] - ETA: 0s - loss: 31.7150 850/1091 [======================>.......] - ETA: 0s - loss: 31.60911050/1091 [===========================>..] - ETA: 0s - loss: 31.5101
Epoch 00004: val_loss did not improve from 60.91054
1091/1091 [==============================] - 0s 295us/sample - loss: 31.4973 - val_loss: 66.8768
Epoch 5/50
  50/1091 [>.............................] - ETA: 0s - loss: 30.6360 250/1091 [=====>........................] - ETA: 0s - loss: 30.1701 450/1091 [===========>..................] - ETA: 0s - loss: 30.2926 650/1091 [================>.............] - ETA: 0s - loss: 30.1759 850/1091 [======================>.......] - ETA: 0s - loss: 29.98701050/1091 [===========================>..] - ETA: 0s - loss: 30.1080
Epoch 00005: val_loss improved from 60.91054 to 59.80631, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 321us/sample - loss: 30.0941 - val_loss: 59.8063
Epoch 6/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.7151 250/1091 [=====>........................] - ETA: 0s - loss: 29.0196 450/1091 [===========>..................] - ETA: 0s - loss: 28.7537 650/1091 [================>.............] - ETA: 0s - loss: 29.2044 850/1091 [======================>.......] - ETA: 0s - loss: 29.29251050/1091 [===========================>..] - ETA: 0s - loss: 29.0960
Epoch 00006: val_loss improved from 59.80631 to 55.47272, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 327us/sample - loss: 29.1479 - val_loss: 55.4727
Epoch 7/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.4514 250/1091 [=====>........................] - ETA: 0s - loss: 28.0186 450/1091 [===========>..................] - ETA: 0s - loss: 28.2187 650/1091 [================>.............] - ETA: 0s - loss: 28.4610 850/1091 [======================>.......] - ETA: 0s - loss: 28.61781050/1091 [===========================>..] - ETA: 0s - loss: 28.3512
Epoch 00007: val_loss improved from 55.47272 to 47.29804, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 328us/sample - loss: 28.3561 - val_loss: 47.2980
Epoch 8/50
  50/1091 [>.............................] - ETA: 0s - loss: 28.6410 250/1091 [=====>........................] - ETA: 0s - loss: 28.2442 450/1091 [===========>..................] - ETA: 0s - loss: 27.8455 650/1091 [================>.............] - ETA: 0s - loss: 27.9439 850/1091 [======================>.......] - ETA: 0s - loss: 27.90851050/1091 [===========================>..] - ETA: 0s - loss: 27.9611
Epoch 00008: val_loss improved from 47.29804 to 38.33127, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 321us/sample - loss: 27.9143 - val_loss: 38.3313
Epoch 9/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.0863 250/1091 [=====>........................] - ETA: 0s - loss: 27.2953 450/1091 [===========>..................] - ETA: 0s - loss: 27.8248 650/1091 [================>.............] - ETA: 0s - loss: 27.8524 850/1091 [======================>.......] - ETA: 0s - loss: 27.94571050/1091 [===========================>..] - ETA: 0s - loss: 27.7070
Epoch 00009: val_loss improved from 38.33127 to 36.19943, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 322us/sample - loss: 27.6625 - val_loss: 36.1994
Epoch 10/50
  50/1091 [>.............................] - ETA: 0s - loss: 27.1184 250/1091 [=====>........................] - ETA: 0s - loss: 26.9075 450/1091 [===========>..................] - ETA: 0s - loss: 27.1095 650/1091 [================>.............] - ETA: 0s - loss: 26.7256 850/1091 [======================>.......] - ETA: 0s - loss: 27.05271050/1091 [===========================>..] - ETA: 0s - loss: 27.0898
Epoch 00010: val_loss improved from 36.19943 to 29.27745, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 326us/sample - loss: 27.0888 - val_loss: 29.2774
Epoch 11/50
  50/1091 [>.............................] - ETA: 0s - loss: 27.6662 250/1091 [=====>........................] - ETA: 0s - loss: 26.7131 450/1091 [===========>..................] - ETA: 0s - loss: 27.3575 550/1091 [==============>...............] - ETA: 0s - loss: 27.2341 750/1091 [===================>..........] - ETA: 0s - loss: 27.1362 950/1091 [=========================>....] - ETA: 0s - loss: 27.1015
Epoch 00011: val_loss improved from 29.27745 to 29.04606, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 364us/sample - loss: 27.2888 - val_loss: 29.0461
Epoch 12/50
  50/1091 [>.............................] - ETA: 0s - loss: 27.4309 250/1091 [=====>........................] - ETA: 0s - loss: 27.5941 450/1091 [===========>..................] - ETA: 0s - loss: 27.3794 650/1091 [================>.............] - ETA: 0s - loss: 27.6335 850/1091 [======================>.......] - ETA: 0s - loss: 27.42871050/1091 [===========================>..] - ETA: 0s - loss: 27.4140
Epoch 00012: val_loss improved from 29.04606 to 28.37807, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 318us/sample - loss: 27.3968 - val_loss: 28.3781
Epoch 13/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.7475 250/1091 [=====>........................] - ETA: 0s - loss: 26.8753 450/1091 [===========>..................] - ETA: 0s - loss: 27.0962 650/1091 [================>.............] - ETA: 0s - loss: 27.0996 850/1091 [======================>.......] - ETA: 0s - loss: 26.94361050/1091 [===========================>..] - ETA: 0s - loss: 26.8887
Epoch 00013: val_loss improved from 28.37807 to 26.78826, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 328us/sample - loss: 26.8556 - val_loss: 26.7883
Epoch 14/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.8430 250/1091 [=====>........................] - ETA: 0s - loss: 26.3244 450/1091 [===========>..................] - ETA: 0s - loss: 25.8068 650/1091 [================>.............] - ETA: 0s - loss: 26.2758 850/1091 [======================>.......] - ETA: 0s - loss: 26.33801050/1091 [===========================>..] - ETA: 0s - loss: 26.5516
Epoch 00014: val_loss improved from 26.78826 to 26.30630, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 322us/sample - loss: 26.5527 - val_loss: 26.3063
Epoch 15/50
  50/1091 [>.............................] - ETA: 0s - loss: 27.0177 250/1091 [=====>........................] - ETA: 0s - loss: 26.7332 450/1091 [===========>..................] - ETA: 0s - loss: 27.0561 650/1091 [================>.............] - ETA: 0s - loss: 26.8507 850/1091 [======================>.......] - ETA: 0s - loss: 26.69221050/1091 [===========================>..] - ETA: 0s - loss: 26.6688
Epoch 00015: val_loss did not improve from 26.30630
1091/1091 [==============================] - 0s 297us/sample - loss: 26.6557 - val_loss: 26.5541
Epoch 16/50
  50/1091 [>.............................] - ETA: 0s - loss: 24.4395 250/1091 [=====>........................] - ETA: 0s - loss: 26.1073 450/1091 [===========>..................] - ETA: 0s - loss: 26.1807 650/1091 [================>.............] - ETA: 0s - loss: 26.1756 850/1091 [======================>.......] - ETA: 0s - loss: 26.35011050/1091 [===========================>..] - ETA: 0s - loss: 26.1421
Epoch 00016: val_loss improved from 26.30630 to 25.66095, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 322us/sample - loss: 26.1748 - val_loss: 25.6609
Epoch 17/50
  50/1091 [>.............................] - ETA: 0s - loss: 26.2099 250/1091 [=====>........................] - ETA: 0s - loss: 25.4648 450/1091 [===========>..................] - ETA: 0s - loss: 25.6214 650/1091 [================>.............] - ETA: 0s - loss: 25.7576 850/1091 [======================>.......] - ETA: 0s - loss: 25.85121050/1091 [===========================>..] - ETA: 0s - loss: 25.8901
Epoch 00017: val_loss improved from 25.66095 to 24.35087, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 326us/sample - loss: 25.8828 - val_loss: 24.3509
Epoch 18/50
  50/1091 [>.............................] - ETA: 0s - loss: 25.7140 250/1091 [=====>........................] - ETA: 0s - loss: 25.9756 450/1091 [===========>..................] - ETA: 0s - loss: 25.8170 650/1091 [================>.............] - ETA: 0s - loss: 26.0378 850/1091 [======================>.......] - ETA: 0s - loss: 25.78321050/1091 [===========================>..] - ETA: 0s - loss: 25.9605
Epoch 00018: val_loss did not improve from 24.35087
1091/1091 [==============================] - 0s 288us/sample - loss: 25.9059 - val_loss: 24.4750
Epoch 19/50
  50/1091 [>.............................] - ETA: 0s - loss: 24.7746 250/1091 [=====>........................] - ETA: 0s - loss: 25.8338 450/1091 [===========>..................] - ETA: 0s - loss: 25.8140 650/1091 [================>.............] - ETA: 0s - loss: 25.6715 750/1091 [===================>..........] - ETA: 0s - loss: 25.5133 950/1091 [=========================>....] - ETA: 0s - loss: 25.6877
Epoch 00019: val_loss improved from 24.35087 to 23.87202, saving model to /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/StartingYear2008/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
1091/1091 [==============================] - 0s 365us/sample - loss: 25.7168 - val_loss: 23.8720
Epoch 20/50
  50/1091 [>.............................] - ETA: 0s - loss: 27.6143 250/1091 [=====>........................] - ETA: 0s - loss: 25.7461 450/1091 [===========>..................] - ETA: 0s - loss: 25.6115 650/1091 [================>.............] - ETA: 0s - loss: 25.7122 850/1091 [======================>.......] - ETA: 0s - loss: 25.64031050/1091 [===========================>..] - ETA: 0s - loss: 25.6526