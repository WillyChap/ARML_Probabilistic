{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "post processing forecast: F048\n",
      "#############################################\n",
      "['/device:GPU:0']\n",
      "#################################################\n",
      "#################################################\n",
      "SUCCESS: Found GPU: /device:GPU:0\n",
      "#################################################\n",
      "#################################################\n",
      "We are here: /glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal\n",
      "/glade/scratch/wchapman/Reforecast/F000\n",
      "/glade/scratch/wchapman/Reforecast/F006\n",
      "/glade/scratch/wchapman/Reforecast/F012\n",
      "/glade/scratch/wchapman/Reforecast/F018\n",
      "/glade/scratch/wchapman/Reforecast/F024\n",
      "/glade/scratch/wchapman/Reforecast/F030\n",
      "/glade/scratch/wchapman/Reforecast/F036\n",
      "/glade/scratch/wchapman/Reforecast/F042\n",
      "/glade/scratch/wchapman/Reforecast/F048\n",
      "Training on\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1985_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1986_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1987_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1988_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1989_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1990_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1991_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1992_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1993_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1994_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1995_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1996_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1997_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1998_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1999_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2000_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2001_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2002_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2003_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2005_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\n",
      "/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\n",
      "Validating on\n",
      "/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\n",
      "Testing on\n",
      "/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\n",
      "['/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc']\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "\n",
      "\n",
      "Mean and standard deviation for \"IVT\" = 148.5128, 131.0735\n",
      "Mean and standard deviation for \"p_sfc\" = 1005.8493, 25.1763\n",
      "Mean and standard deviation for \"u_tr_p\" = 13.2625, 11.8385\n",
      "Mean and standard deviation for \"v_tr_p\" = -0.3258, 14.0102\n",
      "Mean and standard deviation for \"Z_p\" = 5604.4673, 163.6996\n",
      "Mean and standard deviation for \"IWV\" = 12.9654, 5.9766\n",
      "Mean and standard deviation for \"lat\" = 41.7743, 6.9694\n",
      "Mean and standard deviation for \"lon\" = -123.6155, 3.6445\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "\n",
      "\n",
      "Mean and standard deviation for \"IVTm\" = 143.1066, 130.5466\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1985_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1986_500mb_Clean.nc\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/utilsProb.py:216: RuntimeWarning: invalid value encountered in log\n",
      "  post_matrix = numpy.log(post_matrix)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1987_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1988_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1989_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1990_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1991_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1992_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1993_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1994_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1995_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1996_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1997_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1998_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_1999_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2000_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2001_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2002_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2003_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2005_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/utilsProb.py:209: RuntimeWarning: divide by zero encountered in log\n",
      "  predictor_matrix[:,:,:,indicesPRED] = numpy.log(predictor_matrix[:,:,:,indicesPRED])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "number of training samples: 3880\n",
      "number of validation samples: 121\n",
      "number of validation samples: 121\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "### Import Packages ### run in tfp environment: \n",
    "####################################################################################\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "tfd = tfp.distributions\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import math as tfm\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import os\n",
    "\n",
    "import utilsProb\n",
    "import utilsProbSS\n",
    "import comsnn\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "from scipy.stats import rankdata\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import copy\n",
    "from netCDF4 import Dataset, num2date\n",
    "from scipy.interpolate import interpn\n",
    "from matplotlib.colors import Normalize \n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid', {'font.family':'serif', 'font.serif':'Times New Roman'})\n",
    "import properscoring as ps\n",
    "from math import erf\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "#mapping\n",
    "from cartopy import config\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import xarray as xr\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "\n",
    "stepnum=int(9)\n",
    "dirA = ['F'+f'{x:03}' for x in np.arange(0,126,6)]\n",
    "print('#############################################')\n",
    "print('post processing forecast:', dirA[stepnum-1])\n",
    "print('#############################################')\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "#GPU cuda handling: \n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "    print('#################################################')\n",
    "    print('#################################################')\n",
    "    print('WARNING: GPU device not found.')\n",
    "    print('#################################################')\n",
    "    print('#################################################')\n",
    "else:\n",
    "    print('#################################################')\n",
    "    print('#################################################')\n",
    "    print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))\n",
    "    print('#################################################')\n",
    "    print('#################################################')\n",
    "####################################################################################\n",
    "print('We are here:',os.getcwd())\n",
    "os.chdir('/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/')\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "# check region of interest folder\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dd = '/glade/scratch/wchapman/Reforecast/'\n",
    "os.chdir(dd)\n",
    "\n",
    "yago= next(os.walk('.'))[1]\n",
    "yago = sorted(yago)\n",
    "subs = 'F'\n",
    "res = [ii for ii in yago if subs in ii] \n",
    "res\n",
    "for fcast in res[:stepnum]: \n",
    "    os.chdir(dd+'/'+fcast)\n",
    "    print(os.getcwd())\n",
    "    \n",
    "    \n",
    "####################################################################################\n",
    "####################################################################################    \n",
    "    \n",
    "batch_num = 50\n",
    "epochs = 30\n",
    "#find all files in directory                                                                                                                                                  \n",
    "print('Training on')\n",
    "path = os.getcwd()\n",
    "train_file_names = sorted([f for f in glob.glob(path + \"/train/*_500mb_Clean.nc\", recursive=True)])\n",
    "for f in train_file_names:\n",
    "    print(f)\n",
    "\n",
    "print('Validating on')\n",
    "validate_file_names = sorted([f for f in glob.glob(path + \"/validate/*_500mb_Clean.nc\", recursive=True)])\n",
    "for f in validate_file_names:\n",
    "    print(f)\n",
    "    \n",
    "print('Testing on')\n",
    "test_file_names = sorted([f for f in glob.glob(path + \"/test/*_500mb_Clean.nc\", recursive=True)])\n",
    "for f in test_file_names:\n",
    "    print(f)\n",
    "    \n",
    "All_file_names =train_file_names + validate_file_names +test_file_names \n",
    "\n",
    "####################################################################################\n",
    "#years to include in training. \n",
    "####################################################################################\n",
    "# yearstoinclude = ['1985','1986','1987','1988','1989','1990','1991','1992','1993','1994','1995','1996','1997','1998','1999','2000','2001','2002','2003','2004','2005',\n",
    "#                   '2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018']\n",
    "yearstoinclude = ['2004','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018']\n",
    "res=[]\n",
    "for jj in yearstoinclude:\n",
    "    res.append([i for i in All_file_names if jj in i][0])\n",
    "    \n",
    "print(res)\n",
    "\n",
    "####################################################################################\n",
    "#region: \n",
    "####################################################################################\n",
    "\n",
    "rang = 144\n",
    "latlonfolder = '/glade/scratch/wchapman/AnEnCNN_good/Data/WestCoast/'\n",
    "[latsDO,lonsDO,latind, lonind] = utilsProbSS.get_latlon_ind(latlonfolder)\n",
    "latsDO.shape\n",
    "latind = np.array(latind[:rang])\n",
    "lonind = np.array(lonind[:rang])\n",
    "latsDO = np.array(latsDO[:rang])\n",
    "lonsDO = np.array(lonsDO[:rang])\n",
    "\n",
    "norm_dict = utilsProbSS.get_image_normalization_params(res,latind,lonind)\n",
    "sys.stdout.flush()\n",
    "norm_dict_targ = utilsProbSS.get_image_normalization_params_targ(res,latind,lonind)\n",
    "\n",
    "#no scaling the target\n",
    "norm_dict_targ['IVTm'][0]=0\n",
    "norm_dict_targ['IVTm'][1]=1\n",
    "\n",
    "sys.stdout.flush()\n",
    "num_samps_train = utilsProb.count_samps(train_file_names)\n",
    "num_samps_val = utilsProb.count_samps(validate_file_names)\n",
    "num_samps_test = utilsProb.count_samps(test_file_names)\n",
    "\n",
    "print('number of training samples:',num_samps_train)\n",
    "sys.stdout.flush()\n",
    "\n",
    "print('number of validation samples:',num_samps_val)\n",
    "sys.stdout.flush()\n",
    "print('number of validation samples:',num_samps_test)\n",
    "num_samps_tot = num_samps_train+num_samps_val+num_samps_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################\n",
      "testing: ['/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc']\n",
      "validatiing: ['/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc']\n",
      "#################################################\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "...gathering data...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "before shape: (209520, 1)\n",
      "deleting: (0,) values\n",
      "after shape: (209520, 1)\n",
      "before shape test: (17424, 1)\n",
      "deleting test: (0,) values\n",
      "after shape tst: (17424, 1)\n",
      "y_tst: 17424\n",
      "x_tst: 17424\n",
      "...Encoding Stations...\n",
      "...done...\n",
      "In shape:  6\n",
      "Out shape:  1\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 2)         288         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2)            0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8)            0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           270         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 40)           1240        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            82          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,880\n",
      "Trainable params: 1,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2017/cpf_CRPS_val_2016_test_2017.ckpt\n",
      "/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2017/cpf_CRPS_val_2016_test_2017.ckpt\n",
      "#################################################\n",
      "testing: ['/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc']\n",
      "validatiing: ['/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc']\n",
      "#################################################\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "...gathering data...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "before shape: (209520, 1)\n",
      "deleting: (0,) values\n",
      "after shape: (209520, 1)\n",
      "before shape test: (17424, 1)\n",
      "deleting test: (0,) values\n",
      "after shape tst: (17424, 1)\n",
      "y_tst: 17424\n",
      "x_tst: 17424\n",
      "...Encoding Stations...\n",
      "...done...\n",
      "In shape:  6\n",
      "Out shape:  1\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 2)         288         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8)            0           input_4[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           270         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 40)           1240        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            82          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,880\n",
      "Trainable params: 1,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2018/cpf_CRPS_val_2017_test_2018.ckpt\n",
      "/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2018/cpf_CRPS_val_2017_test_2018.ckpt\n",
      "#################################################\n",
      "testing: ['/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc']\n",
      "validatiing: ['/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc']\n",
      "#################################################\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/wchapman/miniconda3/envs/tfp/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "...gathering data...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "before shape: (226944, 1)\n",
      "deleting: (0,) values\n",
      "after shape: (226944, 1)\n",
      "before shape test: (17424, 1)\n",
      "deleting test: (0,) values\n",
      "after shape tst: (17424, 1)\n",
      "y_tst: 17424\n",
      "x_tst: 17424\n",
      "...Encoding Stations...\n",
      "...done...\n",
      "In shape:  6\n",
      "Out shape:  1\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 2)         288         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8)            0           input_7[0][0]                    \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           270         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 40)           1240        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            82          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,880\n",
      "Trainable params: 1,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#Training! \n",
    "####################################################################################\n",
    "\n",
    "allinds = np.arange(len(res))\n",
    "for bb in range(len(res)-3,len(res)):\n",
    "    \n",
    "    if bb == (len(res)-1):\n",
    "        allinds = np.arange(len(res))\n",
    "        test_fil_name = [res[allinds[-3]]]\n",
    "        val_fil_name = [res[allinds[-1]]]\n",
    "        rest = np.delete(allinds,[bb,bb+1])\n",
    "        train_fil_name = np.array(res)[rest].tolist()\n",
    "    else:\n",
    "        allinds = np.arange(len(res))\n",
    "        test_fil_name = [res[allinds[bb+1]]]\n",
    "        val_fil_name = [res[allinds[bb]]]\n",
    "        rest = np.delete(allinds,[bb,bb+1])\n",
    "        train_fil_name = np.array(res)[rest].tolist()\n",
    "    \n",
    "    print('#################################################')\n",
    "    print('testing:',test_fil_name)\n",
    "    print('validatiing:',val_fil_name)\n",
    "    print('#################################################')\n",
    "    \n",
    "    num_samps_train = utilsProb.count_samps(train_fil_name)\n",
    "    num_samps_val = utilsProb.count_samps(val_fil_name)\n",
    "\n",
    "    print('...gathering data...')\n",
    "    aa = utilsProbSS.deep_learning_generator_ss_mv(train_fil_name, num_samps_train*len(latind),norm_dict,norm_dict_targ,targ_LATinds=latind,targ_LONinds=lonind)\n",
    "    adf = next(aa)\n",
    "    x = adf[0]\n",
    "    y = adf[1]\n",
    "    aa = utilsProbSS.deep_learning_generator_ss_mv(val_fil_name, num_samps_val*len(latind),norm_dict,norm_dict_targ,targ_LATinds=latind,targ_LONinds=lonind)\n",
    "    adf = next(aa)\n",
    "    x_tst = adf[0]\n",
    "    y_tst = adf[1]\n",
    "\n",
    "    #remove x and y where x ==0 \n",
    "    rmind = np.where(utilsProbSS.denormalize_images_targ(x[:,0],'IVT',norm_dict)==0)\n",
    "    print('before shape:',y.shape)\n",
    "    print('deleting:',rmind[0].shape,'values')\n",
    "    x = np.delete(x,rmind[0],0)\n",
    "    y = np.delete(y,rmind[0],0)\n",
    "    print('after shape:',y.shape)\n",
    "    \n",
    "    rmind = np.where(utilsProbSS.denormalize_images_targ(x_tst[:,0],'IVT',norm_dict)==0)\n",
    "    print('before shape test:',y_tst.shape)\n",
    "    print('deleting test:',rmind[0].shape,'values')\n",
    "    x_tst = np.delete(x_tst,rmind[0],0)\n",
    "    y_tst = np.delete(y_tst,rmind[0],0)\n",
    "    print('after shape tst:',y_tst.shape)   \n",
    "    \n",
    "    print('y_tst:',y_tst.shape[0])\n",
    "    print('x_tst:',x_tst.shape[0])\n",
    "    print('...Encoding Stations...')\n",
    "\n",
    "    SUMID = np.unique(x[:,6]+x[:,7])\n",
    "    #station ID integers \n",
    "    stID = np.zeros([x.shape[0],1])\n",
    "    for jj,un in enumerate(SUMID):\n",
    "        mats = np.where(x[:,6]+x[:,7]==un)\n",
    "        stID[mats,:] = int(jj)\n",
    "    stID=stID.astype(int)\n",
    "\n",
    "    #station ID integers \n",
    "    stID_tst = np.zeros([x_tst.shape[0],1])\n",
    "    for jj,un in enumerate(SUMID):\n",
    "        mats = np.where(x_tst[:,6]+x_tst[:,7]==un)\n",
    "        stID_tst[mats,:] = int(jj)\n",
    "    stID_tst=stID_tst.astype(int)\n",
    "    print('...done...')\n",
    "\n",
    "    x=x[:,:6]\n",
    "    x_tst=x_tst[:,:6]\n",
    "    \n",
    "    ### Model Build #### \n",
    "    \n",
    "    in_shape = x.shape[1]\n",
    "    print('In shape: ',in_shape)\n",
    "    out_shape = 1\n",
    "    print('Out shape: ',out_shape)    \n",
    "    \n",
    "    max_id = np.max(stID)\n",
    "    \n",
    "    model = comsnn.build_emb_model(in_shape,2,[30,40],2,max_id,compile=True)\n",
    "    \n",
    "    model.summary()\n",
    "    valyr= val_fil_name[0].split('_500mb')[0]\n",
    "    valyr =valyr.split('_')[2]\n",
    "    tstyr= test_fil_name[0].split('_500mb')[0]\n",
    "    tstyr =tstyr.split('_')[2]\n",
    "    #save location:\n",
    "    newdir = '/glade/scratch/wchapman/Reforecast/models/NN_CRPS/' +fcast+'/ONLYTHREE_'+tstyr\n",
    "    if not os.path.exists(newdir):\n",
    "        os.makedirs(newdir)\n",
    "    \n",
    "    Wsave_name = newdir+'/cpf_CRPS_val_'+ valyr+'_test_'+tstyr+'.ckpt'\n",
    "    \n",
    "    print(Wsave_name)\n",
    "    print(Wsave_name)\n",
    "\n",
    "    modsave = tf.keras.callbacks.ModelCheckpoint(Wsave_name, monitor='val_loss', verbose=1, save_best_only=True,save_weights_only=True, mode='min',include_optimizer=False)\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.4,patience=2, min_lr=0.00001,verbose=1)\n",
    "    er_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto',baseline=None, restore_best_weights=False)\n",
    "    net_in = tf.keras.layers.Input(shape=(in_shape))\n",
    "    \n",
    "    #train model\n",
    "    histss = model.fit([x,stID], y,validation_data=([x_tst,stID_tst],y_tst), epochs=200,batch_size=100 ,verbose=True,callbacks=[modsave,reduce_lr,er_stop]);\n",
    "    hist_df = pd.DataFrame(histss.history) \n",
    "   \n",
    "    # or save to csv: \n",
    "    hist_csv_file = newdir+'/fithist_CRPS_'+ valyr+'_test_'+tstyr+'.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune on previous years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('xnan:',np.sum(np.isnan(x)))\n",
    "print('ynan:',np.sum(np.isnan(y)))\n",
    "\n",
    "print('x_tstnan:',np.sum(np.isnan(x_tst)))\n",
    "print('y_tstnan:',np.sum(np.isnan(y_tst)))\n",
    "####################################################################################\n",
    "#finally fine tuning it. \n",
    "####################################################################################\n",
    "\n",
    "        \n",
    "yearstoinclude = ['2016','2017','2018']\n",
    "res=[]\n",
    "for jj in yearstoinclude:\n",
    "    res.append([i for i in All_file_names if jj in i][0])\n",
    "    \n",
    "print(res)\n",
    "\n",
    "####################################################################################\n",
    "#finally fine tuning it. \n",
    "####################################################################################\n",
    "\n",
    "All_file_names\n",
    "\n",
    "allinds = np.arange(len(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################\n",
      "testing: ['/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc']\n",
      "validatiing: ['/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc']\n",
      "#################################################\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "...gathering data...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "before shape: (209520, 1)\n",
      "deleting: (0,) values\n",
      "after shape: (209520, 1)\n",
      "before shape test: (17424, 1)\n",
      "deleting test: (0,) values\n",
      "after shape tst: (17424, 1)\n",
      "y_tst: 17424\n",
      "x_tst: 17424\n",
      "...Encoding Stations...\n",
      "...done...\n",
      "In shape:  6\n",
      "Out shape:  1\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### layers frozen ###########\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2b8d61da1208> False\n",
      "<tensorflow.python.keras.layers.embeddings.Embedding object at 0x2b8d61da1358> False\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2b8d61da1160> False\n",
      "<tensorflow.python.keras.layers.core.Flatten object at 0x2b8d61da1f98> False\n",
      "<tensorflow.python.keras.layers.merge.Concatenate object at 0x2b8d61da1b38> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2b8d61da1f60> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2b8d61d8d978> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2b8d61da1438> False\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         288         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8)            0           input_10[0][0]                   \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           270         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 40)           1240        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            82          dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "Total params: 3,760\n",
      "Trainable params: 1,880\n",
      "Non-trainable params: 1,880\n",
      "__________________________________________________________________________________________________\n",
      "#################################################\n",
      "testing: ['/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc']\n",
      "validatiing: ['/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc']\n",
      "#################################################\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "...gathering data...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "before shape: (209520, 1)\n",
      "deleting: (0,) values\n",
      "after shape: (209520, 1)\n",
      "before shape test: (17424, 1)\n",
      "deleting test: (0,) values\n",
      "after shape tst: (17424, 1)\n",
      "y_tst: 17424\n",
      "x_tst: 17424\n",
      "...Encoding Stations...\n",
      "...done...\n",
      "In shape:  6\n",
      "Out shape:  1\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### layers frozen ###########\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2b8d7ff9fb00> False\n",
      "<tensorflow.python.keras.layers.embeddings.Embedding object at 0x2b8d7ff9fc50> False\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2b8d7ff9fa90> False\n",
      "<tensorflow.python.keras.layers.core.Flatten object at 0x2b8d7ff9f8d0> False\n",
      "<tensorflow.python.keras.layers.merge.Concatenate object at 0x2b8d57b722e8> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2b8d7ff9fcc0> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2b8d7f171940> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2b8d61da4390> False\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 2)         288         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8)            0           input_12[0][0]                   \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 30)           270         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 40)           1240        dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2)            82          dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,760\n",
      "Trainable params: 1,880\n",
      "Non-trainable params: 1,880\n",
      "__________________________________________________________________________________________________\n",
      "#################################################\n",
      "testing: ['/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc']\n",
      "validatiing: ['/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc']\n",
      "#################################################\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/wchapman/miniconda3/envs/tfp/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "...gathering data...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2013_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2015_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2004_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2009_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2012_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2011_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2016_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2006_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2014_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2010_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2007_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/train/F048_WY_2008_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/validate/F048_WY_2017_500mb_Clean.nc\"...\n",
      "Reading data from: \"/glade/scratch/wchapman/Reforecast/F048/test/F048_WY_2018_500mb_Clean.nc\"...\n",
      "before shape: (226944, 1)\n",
      "deleting: (0,) values\n",
      "after shape: (226944, 1)\n",
      "before shape test: (17424, 1)\n",
      "deleting test: (0,) values\n",
      "after shape tst: (17424, 1)\n",
      "y_tst: 17424\n",
      "x_tst: 17424\n",
      "...Encoding Stations...\n",
      "...done...\n",
      "In shape:  6\n",
      "Out shape:  1\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F048/ONLYTHREE_2016/cpf_CRPS_val_2018_test_2016.ckpt\n",
      "########### layers frozen ###########\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2b8dcddfa668> False\n",
      "<tensorflow.python.keras.layers.embeddings.Embedding object at 0x2b8dcddfa518> False\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x2b8dcddfa710> False\n",
      "<tensorflow.python.keras.layers.core.Flatten object at 0x2b8dcddfa128> False\n",
      "<tensorflow.python.keras.layers.merge.Concatenate object at 0x2b8dcddfa358> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2b8dcddfa0f0> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2b8dcde000b8> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x2b8d7ffaf358> False\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 2)         288         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8)            0           input_14[0][0]                   \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 30)           270         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 40)           1240        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            82          dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,760\n",
      "Trainable params: 1,880\n",
      "Non-trainable params: 1,880\n",
      "__________________________________________________________________________________________________\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for bb in range(len(res)-3,len(res)):\n",
    "    \n",
    "    if bb == (len(res)-1):\n",
    "        allinds = np.arange(len(res))\n",
    "        test_fil_name = [res[allinds[-3]]]\n",
    "        val_fil_name = [res[allinds[-1]]]\n",
    "        rest = np.delete(allinds,[bb,bb+1])\n",
    "        train_fil_name = np.array(res)[rest].tolist()\n",
    "    else:\n",
    "        allinds = np.arange(len(res))\n",
    "        test_fil_name = [res[allinds[bb+1]]]\n",
    "        val_fil_name = [res[allinds[bb]]]\n",
    "        rest = np.delete(allinds,[bb,bb+1])\n",
    "        train_fil_name = np.array(res)[rest].tolist()\n",
    "    \n",
    "    print('#################################################')\n",
    "    print('testing:',test_fil_name)\n",
    "    print('validatiing:',val_fil_name)\n",
    "    print('#################################################')\n",
    "    \n",
    "    num_samps_train = utilsProb.count_samps(train_fil_name)\n",
    "    num_samps_val = utilsProb.count_samps(val_fil_name)\n",
    "\n",
    "    print('...gathering data...')\n",
    "    aa = utilsProbSS.deep_learning_generator_ss_mv(train_fil_name, num_samps_train*len(latind),norm_dict,norm_dict_targ,targ_LATinds=latind,targ_LONinds=lonind)\n",
    "    adf = next(aa)\n",
    "    x = adf[0]\n",
    "    y = adf[1]\n",
    "    aa = utilsProbSS.deep_learning_generator_ss_mv(val_fil_name, num_samps_val*len(latind),norm_dict,norm_dict_targ,targ_LATinds=latind,targ_LONinds=lonind)\n",
    "    adf = next(aa)\n",
    "    x_tst = adf[0]\n",
    "    y_tst = adf[1]\n",
    "\n",
    "    #remove x and y where x ==0 \n",
    "    rmind = np.where(utilsProbSS.denormalize_images_targ(x[:,0],'IVT',norm_dict)==0)\n",
    "    print('before shape:',y.shape)\n",
    "    print('deleting:',rmind[0].shape,'values')\n",
    "    x = np.delete(x,rmind[0],0)\n",
    "    y = np.delete(y,rmind[0],0)\n",
    "    print('after shape:',y.shape)\n",
    "    \n",
    "    rmind = np.where(utilsProbSS.denormalize_images_targ(x_tst[:,0],'IVT',norm_dict)==0)\n",
    "    print('before shape test:',y_tst.shape)\n",
    "    print('deleting test:',rmind[0].shape,'values')\n",
    "    x_tst = np.delete(x_tst,rmind[0],0)\n",
    "    y_tst = np.delete(y_tst,rmind[0],0)\n",
    "    print('after shape tst:',y_tst.shape)   \n",
    "    \n",
    "    print('y_tst:',y_tst.shape[0])\n",
    "    print('x_tst:',x_tst.shape[0])\n",
    "    print('...Encoding Stations...')\n",
    "\n",
    "    SUMID = np.unique(x[:,6]+x[:,7])\n",
    "    #station ID integers \n",
    "    stID = np.zeros([x.shape[0],1])\n",
    "    for jj,un in enumerate(SUMID):\n",
    "        mats = np.where(x[:,6]+x[:,7]==un)\n",
    "        stID[mats,:] = int(jj)\n",
    "    stID=stID.astype(int)\n",
    "\n",
    "    #station ID integers \n",
    "    stID_tst = np.zeros([x_tst.shape[0],1])\n",
    "    for jj,un in enumerate(SUMID):\n",
    "        mats = np.where(x_tst[:,6]+x_tst[:,7]==un)\n",
    "        stID_tst[mats,:] = int(jj)\n",
    "    stID_tst=stID_tst.astype(int)\n",
    "    print('...done...')\n",
    "\n",
    "    x=x[:,:6]\n",
    "    x_tst=x_tst[:,:6]\n",
    "    \n",
    "    ### Model Build #### \n",
    "    \n",
    "    in_shape = x.shape[1]\n",
    "    print('In shape: ',in_shape)\n",
    "    out_shape = 1\n",
    "    print('Out shape: ',out_shape)    \n",
    "    \n",
    "    max_id = np.max(stID)\n",
    "    \n",
    "    model = comsnn.build_emb_model(in_shape,2,[30,40],2,max_id,compile=True)\n",
    "        \n",
    "    \n",
    "    print('########### Loading old model weights name:',Wsave_name)\n",
    "    print('########### Loading old model weights name:',Wsave_name)\n",
    "    print('########### Loading old model weights name:',Wsave_name)\n",
    "    print('########### Loading old model weights name:',Wsave_name)\n",
    "    print('########### Loading old model weights name:',Wsave_name)\n",
    "    \n",
    "    newdir = '/glade/scratch/wchapman/Reforecast/models/NN_CRPS/' +fcast+'/ONLYTHREE_'+tstyr\n",
    "    Wsave_name = newdir+'/cpf_CRPS_val_'+ valyr+'_test_'+tstyr+'.ckpt'\n",
    "\n",
    "    print('########### layers frozen ###########')\n",
    "    ### CHANGE THIS FOR PRODUCTION RUNS ###########\n",
    "    model.load_weights(Wsave_name)\n",
    "    ### CHANGE THIS FOR PRODUCTION RUNS ###########\n",
    "    for layer in model.layers[:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Check the trainable status of the individual layers\n",
    "\n",
    "    for layer in model.layers:\n",
    "        print(layer, layer.trainable)\n",
    "        \n",
    "        \n",
    "    newout  = tf.keras.layers.Dense(32,activation='relu',padding='same')(model.layers[-1].output)\n",
    "    newout  = tf.keras.layers.Dense(2,activation='linear',padding='same')(newout)\n",
    "    model = tf.keras.models.Model(inputs = model.inputs, outputs = newout)\n",
    "    opt = optimizer=tf.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer='adam', loss=coms.crps_cost_function)\n",
    "    model.summary()\n",
    "    \n",
    "    model.summary()\n",
    "#     valyr= val_fil_name[0].split('_500mb')[0]\n",
    "#     valyr =valyr.split('_')[2]\n",
    "#     tstyr= test_fil_name[0].split('_500mb')[0]\n",
    "#     tstyr =tstyr.split('_')[2]\n",
    "#     #save location:\n",
    "#     newdir = '/glade/scratch/wchapman/Reforecast/models/NN_CRPS/' +fcast+'/ONLYTHREE_'+tstyr\n",
    "#     if not os.path.exists(newdir):\n",
    "#         os.makedirs(newdir)\n",
    "    \n",
    "#     Wsave_name = newdir+'/cpf_CRPS_val_'+ valyr+'_test_FINETUNE_'+tstyr+'.ckpt'\n",
    "    \n",
    "#     print(Wsave_name)\n",
    "#     print(Wsave_name)\n",
    "\n",
    "#     modsave = tf.keras.callbacks.ModelCheckpoint(Wsave_name, monitor='val_loss', verbose=1, save_best_only=True,save_weights_only=True, mode='min',include_optimizer=False)\n",
    "#     reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.4,patience=2, min_lr=0.00001,verbose=1)\n",
    "#     er_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto',baseline=None, restore_best_weights=False)\n",
    "#     net_in = tf.keras.layers.Input(shape=(in_shape))\n",
    "    \n",
    "#     #train model\n",
    "#     histss = model.fit([x,stID], y,validation_data=([x_tst,stID_tst],y_tst), epochs=200,batch_size=100 ,verbose=True,callbacks=[modsave,reduce_lr,er_stop]);\n",
    "#     hist_df = pd.DataFrame(histss.history) \n",
    "   \n",
    "#     # or save to csv: \n",
    "#     hist_csv_file = newdir+'/fithist_FINETUNE_CRPS_'+ valyr+'_test_'+tstyr+'.csv'\n",
    "#     with open(hist_csv_file, mode='w') as f:\n",
    "#         hist_df.to_csv(f)\n",
    "\n",
    "\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp)",
   "language": "python",
   "name": "tfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
