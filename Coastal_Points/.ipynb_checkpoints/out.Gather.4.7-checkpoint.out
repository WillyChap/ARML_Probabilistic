2020-11-09 19:55:34.886813: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-11-09 19:55:34.895148: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2020-11-09 19:55:34.895319: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561d2003aa40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-09 19:55:34.895338: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-09 19:55:34.897133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-11-09 19:55:35.029634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 19:55:35.047456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 19:55:35.169205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 19:55:35.235392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 19:55:35.370996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 19:55:35.500666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 19:55:35.592709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 19:55:35.685482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 19:55:35.688956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 19:55:35.689060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 19:55:35.888577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-09 19:55:35.888692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-11-09 19:55:35.888713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-11-09 19:55:35.895997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 30591 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
2020-11-09 19:55:35.898908: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561d20db6010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-11-09 19:55:35.898956: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-11-09 19:55:35.904768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 19:55:35.904936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 19:55:35.904959: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 19:55:35.904978: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 19:55:35.911113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 19:55:35.911172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 19:55:35.911193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 19:55:35.911214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 19:55:35.915181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 19:55:35.915328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-09 19:55:35.915346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-11-09 19:55:35.915360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-11-09 19:55:35.918724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 30591 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
2020-11-09 19:55:35.923255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 19:55:35.923351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 19:55:35.923371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 19:55:35.923387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 19:55:35.923402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 19:55:35.923418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 19:55:35.923433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 19:55:35.923448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 19:55:35.926583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 19:55:35.926627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-09 19:55:35.926639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-11-09 19:55:35.926648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-11-09 19:55:35.929796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 30591 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
#############################################
post processing forecast: F018
#############################################
['/device:GPU:0']
#################################################
#################################################
SUCCESS: Found GPU: /device:GPU:0
#################################################
#################################################
We are here: /glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal
...Searching...: /glade/scratch/wchapman/AnEnCNN_good/Data/WestCoast/
/glade/scratch/wchapman/Reforecast/F000
/glade/scratch/wchapman/Reforecast/F006
/glade/scratch/wchapman/Reforecast/F012
/glade/scratch/wchapman/Reforecast/F018
Training on
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1985_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1986_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1987_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1988_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1989_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1990_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1991_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1992_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1993_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1994_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1995_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1996_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1997_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1998_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_1999_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2000_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2001_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2002_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2003_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2004_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2005_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2006_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2007_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2008_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2009_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2010_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc
/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc
Validating on
/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc
Testing on
/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc
['2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']
trainging yearss ['/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc']
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...


Mean and standard deviation for "IVT" = 162.5202, 155.5039
Mean and standard deviation for "p_sfc" = 984.8862, 62.0783
Mean and standard deviation for "u_tr_p" = 11.9893, 12.4178
Mean and standard deviation for "v_tr_p" = 1.1301, 13.4873
Mean and standard deviation for "Z_p" = 5586.4391, 204.0330
Mean and standard deviation for "IWV" = 13.8156, 8.0162
2020-11-09 19:55:42.946506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 19:55:42.946656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 19:55:42.946677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 19:55:42.946693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 19:55:42.946709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 19:55:42.946724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 19:55:42.946740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 19:55:42.946755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 19:55:42.949958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 19:55:42.952283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2020-11-09 19:55:42.952364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-11-09 19:55:42.952383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-11-09 19:55:42.952398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-11-09 19:55:42.952413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-11-09 19:55:42.952428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-11-09 19:55:42.952444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-11-09 19:55:42.952460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 19:55:42.956399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-11-09 19:55:42.956458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-09 19:55:42.956470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-11-09 19:55:42.956480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-11-09 19:55:42.959677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30591 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
2020-11-09 19:55:48.660713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-09 19:55:52.125026: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-11-09 19:55:52.143854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
/glade/work/wchapman/miniconda3/envs/tfp/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  data = yaml.load(f.read()) or {}
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/utilsProb.py:216: RuntimeWarning: invalid value encountered in log
  post_matrix = numpy.log(post_matrix)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in double_scalars
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:491: RuntimeWarning: overflow encountered in exp
  m = np.exp(mu + sigma**2 / 2.0)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in exp
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/utilsProb.py:216: RuntimeWarning: invalid value encountered in log
  post_matrix = numpy.log(post_matrix)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:491: RuntimeWarning: overflow encountered in exp
  m = np.exp(mu + sigma**2 / 2.0)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in exp
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in double_scalars
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/utilsProb.py:216: RuntimeWarning: invalid value encountered in log
  post_matrix = numpy.log(post_matrix)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in exp
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in double_scalars
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:491: RuntimeWarning: overflow encountered in exp
  m = np.exp(mu + sigma**2 / 2.0)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/utilsProb.py:216: RuntimeWarning: invalid value encountered in log
  post_matrix = numpy.log(post_matrix)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in double_scalars
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:491: RuntimeWarning: overflow encountered in exp
  m = np.exp(mu + sigma**2 / 2.0)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in exp
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/utilsProb.py:216: RuntimeWarning: invalid value encountered in log
  post_matrix = numpy.log(post_matrix)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:491: RuntimeWarning: overflow encountered in exp
  m = np.exp(mu + sigma**2 / 2.0)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in exp
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in double_scalars
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/utilsProb.py:216: RuntimeWarning: invalid value encountered in log
  post_matrix = numpy.log(post_matrix)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in exp
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:492: RuntimeWarning: overflow encountered in double_scalars
  v = np.exp(2 * mu + sigma**2) * (np.exp(sigma**2) - 1)
/glade/work/wchapman/AnEn/CNN/Coastal_Points_LogNormal/coms.py:491: RuntimeWarning: overflow encountered in exp
  m = np.exp(mu + sigma**2 / 2.0)
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...


Mean and standard deviation for "IVTm" = 203.8212, 179.8134
######### ASSEMBLE!!!! ###########
########### DONE!!!! #############
#################################################
testing: ['/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc']
validatiing: ['/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc']
#################################################
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
...gathering data...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d (ZeroPadding2D)  (None, 72, 60, 6)    0           input_1[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d[0][0]             
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d[0][0]              
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add (Add)                       (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add[0][0]                        
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate[0][0]                
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d (Cropping2D)         (None, 71, 57, 2)    0           linear[0][0]                     
==================================================================================================
Total params: 35,506
Trainable params: 35,442
Non-trainable params: 64
__________________________________________________________________________________________________
########### model name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/StartingYear2011/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
########### model name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/StartingYear2011/CNN_2017/cpf_CRPS_val_2016_test_2017.ckpt
...binned spread skill...
RMSE PP: 31.203580339056845
RMSE WWRF: 31.372569691051137
CRMSE PP: 31.063247085195115
CRMSE WWRF: 30.981578480113637
BIAS PP: -2.956019552121802
BIAS WWRF: 4.937607
#################################################
testing: ['/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc']
validatiing: ['/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc']
#################################################
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
...gathering data...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 72, 60, 6)    0           input_2[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add_1 (Add)                     (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add_1[0][0]                      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate_1[0][0]              
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 71, 57, 2)    0           linear[0][0]                     
==================================================================================================
Total params: 35,506
Trainable params: 35,442
Non-trainable params: 64
__________________________________________________________________________________________________
########### model name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/StartingYear2011/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
########### model name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/StartingYear2011/CNN_2018/cpf_CRPS_val_2017_test_2018.ckpt
...binned spread skill...
RMSE PP: 36.42546716118784
RMSE WWRF: 37.303873697916664
CRMSE PP: 36.28535747978685
CRMSE WWRF: 36.90182957504735
BIAS PP: -3.19177189521335
BIAS WWRF: 5.462021
#################################################
testing: ['/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc']
validatiing: ['/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc']
#################################################
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...
...gathering data...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2014_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2011_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2012_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2015_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2013_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d_2 (ZeroPadding2D (None, 72, 60, 6)    0           input_3[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d_2[0][0]           
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add_2 (Add)                     (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add_2[0][0]                      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate_2[0][0]              
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d_2 (Cropping2D)       (None, 71, 57, 2)    0           linear[0][0]                     
==================================================================================================
Total params: 35,506
Trainable params: 35,442
Non-trainable params: 64
__________________________________________________________________________________________________
########### model name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/StartingYear2011/CNN_2016/cpf_CRPS_val_2018_test_2016.ckpt
########### model name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/StartingYear2011/CNN_2016/cpf_CRPS_val_2018_test_2016.ckpt
...binned spread skill...
RMSE PP: 36.274574364487805
RMSE WWRF: 40.539913293087125
CRMSE PP: 36.26223384919632
CRMSE WWRF: 40.18013879024621
BIAS PP: -0.946109992933458
BIAS WWRF: 5.388962
IVTm shape: (52272,)
IVT mean shape: (52272,)
IVT std shape: (52272,)
                     time         OBS       Model     IVTmean     IVTstd   lat      lon
0     2016-12-01 18:00:00  184.590820  159.781387  138.107224  24.503733  30.0 -116.875
1     2016-12-02 18:00:00  147.514160  174.106659  122.235260  20.508455  30.0 -116.875
2     2016-12-03 18:00:00  146.341476  161.900360  143.567108  21.165401  30.0 -116.875
3     2016-12-04 18:00:00   75.789398   97.923370   73.924210  14.825528  30.0 -116.875
4     2016-12-05 18:00:00  169.267166  136.427673  132.314484  22.447384  30.0 -116.875
...                   ...         ...         ...         ...        ...   ...      ...
52267 2019-03-27 18:00:00   46.782021   63.378578   33.080997  11.611324  55.0 -130.000
52268 2019-03-28 18:00:00   41.938248   48.086823   38.224789  13.249985  55.0 -130.000
52269 2019-03-29 18:00:00    7.441874    2.230743   18.003664   8.145513  55.0 -130.000
52270 2019-03-30 18:00:00   11.097689   24.017746   21.127745   8.499047  55.0 -130.000
52271 2019-03-31 18:00:00   15.704780   23.878815   19.261391   7.429993  55.0 -130.000

[52272 rows x 7 columns]
time       0
OBS        0
Model      0
IVTmean    0
IVTstd     0
lat        0
lon        0
dtype: int64
                OBS         Model       IVTmean        IVTstd           lat           lon
count  52272.000000  52272.000000  52272.000000  52272.000000  52272.000000  52272.000000
mean     141.720118    146.982976    139.355479     27.835133     41.774306   -123.615451
std      134.493739    134.987034    125.472440     20.319833      6.969452      3.644501
min        0.256537      0.834091      7.271719      3.052798     30.000000   -130.000000
25%       49.128183     52.631275     50.661810     13.491839     35.875000   -125.000000
50%       98.764782    105.308067     97.778946     21.341434     41.750000   -124.375000
75%      187.789307    194.870945    187.043140     35.601297     47.625000   -121.875000
max     1222.075684   1224.140625   1050.964844    185.897003     55.000000   -115.625000
['/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc', '/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc']
######### ASSEMBLE!!!! ###########
########### DONE!!!! #############
#################################################
testing: ['/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc']
validatiing: ['/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc']
#################################################
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
...gathering data...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
Model: "model_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d_3 (ZeroPadding2D (None, 72, 60, 6)    0           input_4[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d_3[0][0]           
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add_3 (Add)                     (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add_3[0][0]                      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate_3[0][0]              
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d_3 (Cropping2D)       (None, 71, 57, 2)    0           linear[0][0]                     
==================================================================================================
Total params: 35,506
Trainable params: 35,442
Non-trainable params: 64
__________________________________________________________________________________________________
Model: "model_4"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d_3 (ZeroPadding2D (None, 72, 60, 6)    0           input_4[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d_3[0][0]           
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add_3 (Add)                     (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add_3[0][0]                      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate_3[0][0]              
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d_3 (Cropping2D)       (None, 71, 57, 2)    0           linear[0][0]                     
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 71, 57, 32)   608         cropping2d_3[0][0]               
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 71, 57, 2)    578         conv2d[0][0]                     
==================================================================================================
Total params: 36,692
Trainable params: 36,628
Non-trainable params: 64
__________________________________________________________________________________________________
########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/StartingYear2011/CNN_2017/cpf_CRPS_FINETUNE_val_2016_test_2017.ckpt
...binned spread skill...
RMSE PP: 31.49240532913015
RMSE WWRF: 31.372569691051137
CRMSE PP: 31.45127965316063
CRMSE WWRF: 30.981578480113637
BIAS PP: -1.608900213427674
BIAS WWRF: 4.937607
#################################################
testing: ['/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc']
validatiing: ['/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc']
#################################################
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
...gathering data...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...
Model: "model_5"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d_4 (ZeroPadding2D (None, 72, 60, 6)    0           input_5[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d_4[0][0]           
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add_4 (Add)                     (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add_4[0][0]                      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate_4[0][0]              
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d_4 (Cropping2D)       (None, 71, 57, 2)    0           linear[0][0]                     
==================================================================================================
Total params: 35,506
Trainable params: 35,442
Non-trainable params: 64
__________________________________________________________________________________________________
Model: "model_6"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d_4 (ZeroPadding2D (None, 72, 60, 6)    0           input_5[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d_4[0][0]           
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add_4 (Add)                     (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add_4[0][0]                      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate_4[0][0]              
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d_4 (Cropping2D)       (None, 71, 57, 2)    0           linear[0][0]                     
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 71, 57, 32)   608         cropping2d_4[0][0]               
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 71, 57, 2)    578         conv2d_2[0][0]                   
==================================================================================================
Total params: 36,692
Trainable params: 36,628
Non-trainable params: 64
__________________________________________________________________________________________________
########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/StartingYear2011/CNN_2018/cpf_CRPS_FINETUNE_val_2017_test_2018.ckpt
...binned spread skill...
RMSE PP: 36.40869015135511
RMSE WWRF: 37.303873697916664
CRMSE PP: 36.374056244018654
CRMSE WWRF: 36.90182957504735
BIAS PP: -1.5876644204470836
BIAS WWRF: 5.462021
#################################################
testing: ['/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc']
validatiing: ['/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc']
#################################################
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/test/F018_WY_2018_500mb_Clean.nc"...
...gathering data...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/validate/F018_WY_2017_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Reading data from: "/glade/scratch/wchapman/Reforecast/F018/train/F018_WY_2016_500mb_Clean.nc"...
Model: "model_7"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d_5 (ZeroPadding2D (None, 72, 60, 6)    0           input_6[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d_5[0][0]           
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)  (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d_5[0][0]            
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add_5[0][0]                      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate_5[0][0]              
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d_5 (Cropping2D)       (None, 71, 57, 2)    0           linear[0][0]                     
==================================================================================================
Total params: 35,506
Trainable params: 35,442
Non-trainable params: 64
__________________________________________________________________________________________________
Model: "model_8"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            [(None, 71, 57, 6)]  0                                            
__________________________________________________________________________________________________
zero_padding2d_5 (ZeroPadding2D (None, 72, 60, 6)    0           input_6[0][0]                    
__________________________________________________________________________________________________
downsampling_0_conv_0 (Conv2D)  (None, 72, 60, 16)   880         zero_padding2d_5[0][0]           
__________________________________________________________________________________________________
downsampling_0_batchnorm_0 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_0[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_0 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_0[0][0] 
__________________________________________________________________________________________________
downsampling_0_conv_1 (Conv2D)  (None, 72, 60, 16)   2320        downsampling_0_activation_0[0][0]
__________________________________________________________________________________________________
downsampling_0_batchnorm_1 (Bat (None, 72, 60, 16)   64          downsampling_0_conv_1[0][0]      
__________________________________________________________________________________________________
downsampling_0_activation_1 (Ac (None, 72, 60, 16)   0           downsampling_0_batchnorm_1[0][0] 
__________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)  (None, 36, 30, 16)   0           downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
bottleneck_skip_0 (Conv2D)      (None, 36, 30, 32)   4640        max_pooling2d_5[0][0]            
__________________________________________________________________________________________________
bottleneck_skip_1 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_0[0][0]          
__________________________________________________________________________________________________
bottleneck_skip_2 (Conv2D)      (None, 36, 30, 32)   9248        bottleneck_skip_1[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 36, 30, 32)   0           bottleneck_skip_0[0][0]          
                                                                 bottleneck_skip_1[0][0]          
                                                                 bottleneck_skip_2[0][0]          
__________________________________________________________________________________________________
upsampling_0_conv_trans_0 (Conv (None, 72, 60, 16)   2064        add_5[0][0]                      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 72, 60, 32)   0           upsampling_0_conv_trans_0[0][0]  
                                                                 downsampling_0_activation_1[0][0]
__________________________________________________________________________________________________
upsampling_0_conv_0 (Conv2D)    (None, 72, 60, 16)   4624        concatenate_5[0][0]              
__________________________________________________________________________________________________
upsampling_0_activation_0 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_0[0][0]        
__________________________________________________________________________________________________
upsampling_0_conv_1 (Conv2D)    (None, 72, 60, 16)   2320        upsampling_0_activation_0[0][0]  
__________________________________________________________________________________________________
upsampling_0_activation_1 (Acti (None, 72, 60, 16)   0           upsampling_0_conv_1[0][0]        
__________________________________________________________________________________________________
linear (Conv2D)                 (None, 72, 60, 2)    34          upsampling_0_activation_1[0][0]  
__________________________________________________________________________________________________
cropping2d_5 (Cropping2D)       (None, 71, 57, 2)    0           linear[0][0]                     
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 71, 57, 32)   608         cropping2d_5[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 71, 57, 2)    578         conv2d_4[0][0]                   
==================================================================================================
Total params: 36,692
Trainable params: 36,628
Non-trainable params: 64
__________________________________________________________________________________________________
########### Loading old model weights name: /glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/StartingYear2011/CNN_2016/cpf_CRPS_FINETUNE_val_2018_test_2016.ckpt
...binned spread skill...
RMSE PP: 35.91627704985403
RMSE WWRF: 40.539913293087125
CRMSE PP: 35.9148241973845
CRMSE WWRF: 40.18013879024621
BIAS PP: 0.3230444290311709
BIAS WWRF: 5.388962
IVTm shape: (52272,)
IVT mean shape: (52272,)
IVT std shape: (52272,)
#############################################################################
############## *I hope that is okay baby* - gale beggy ######################
#############################################################################
done
                     time         OBS       Model     IVTmean     IVTstd   lat      lon
0     2016-12-01 18:00:00  184.590820  159.781387  134.860458  21.737131  30.0 -116.875
1     2016-12-02 18:00:00  147.514160  174.106659  120.244278  21.342348  30.0 -116.875
2     2016-12-03 18:00:00  146.341476  161.900360  144.358643  18.849617  30.0 -116.875
3     2016-12-04 18:00:00   75.789398   97.923370   75.087082  12.225684  30.0 -116.875
4     2016-12-05 18:00:00  169.267166  136.427673  132.637039  18.015251  30.0 -116.875
...                   ...         ...         ...         ...        ...   ...      ...
52267 2019-03-27 18:00:00   46.782021   63.378578   32.152916  11.798360  55.0 -130.000
52268 2019-03-28 18:00:00   41.938248   48.086823   37.467094  12.920731  55.0 -130.000
52269 2019-03-29 18:00:00    7.441874    2.230743   18.250740   8.518331  55.0 -130.000
52270 2019-03-30 18:00:00   11.097689   24.017746   20.641150   8.515206  55.0 -130.000
52271 2019-03-31 18:00:00   15.704780   23.878815   19.501461   7.785987  55.0 -130.000

[52272 rows x 7 columns]
time       0
OBS        0
Model      0
IVTmean    0
IVTstd     0
lat        0
lon        0
dtype: int64
                OBS         Model       IVTmean        IVTstd           lat           lon
count  52272.000000  52272.000000  52272.000000  52272.000000  52272.000000  52272.000000
mean     141.720118    146.982976    140.762273     26.504207     41.774306   -123.615451
std      134.493739    134.987034    125.949314     19.432081      6.969452      3.644501
min        0.256537      0.834091      6.986831      4.392865     30.000000   -130.000000
25%       49.128183     52.631275     51.787723     12.815686     35.875000   -125.000000
50%       98.764782    105.308067     99.194122     20.231210     41.750000   -124.375000
75%      187.789307    194.870945    188.895409     33.694567     47.625000   -121.875000
max     1222.075684   1224.140625   1067.446411    169.928848     55.000000   -115.625000
                     time         OBS       Model     IVTmean     IVTstd   lat      lon
0     2016-12-01 18:00:00  184.590820  159.781387  138.107224  24.503733  30.0 -116.875
1     2016-12-02 18:00:00  147.514160  174.106659  122.235260  20.508455  30.0 -116.875
2     2016-12-03 18:00:00  146.341476  161.900360  143.567108  21.165401  30.0 -116.875
3     2016-12-04 18:00:00   75.789398   97.923370   73.924210  14.825528  30.0 -116.875
4     2016-12-05 18:00:00  169.267166  136.427673  132.314484  22.447384  30.0 -116.875
...                   ...         ...         ...         ...        ...   ...      ...
52267 2019-03-27 18:00:00   46.782021   63.378578   33.080997  11.611324  55.0 -130.000
52268 2019-03-28 18:00:00   41.938248   48.086823   38.224789  13.249985  55.0 -130.000
52269 2019-03-29 18:00:00    7.441874    2.230743   18.003664   8.145513  55.0 -130.000
52270 2019-03-30 18:00:00   11.097689   24.017746   21.127745   8.499047  55.0 -130.000
52271 2019-03-31 18:00:00   15.704780   23.878815   19.261391   7.429993  55.0 -130.000

[52272 rows x 7 columns]
time       0
OBS        0
Model      0
IVTmean    0
IVTstd     0
lat        0
lon        0
dtype: int64
                OBS         Model       IVTmean        IVTstd           lat           lon
count  52272.000000  52272.000000  52272.000000  52272.000000  52272.000000  52272.000000
mean     141.720118    146.982976    139.355479     27.835133     41.774306   -123.615451
std      134.493739    134.987034    125.472440     20.319833      6.969452      3.644501
min        0.256537      0.834091      7.271719      3.052798     30.000000   -130.000000
25%       49.128183     52.631275     50.661810     13.491839     35.875000   -125.000000
50%       98.764782    105.308067     97.778946     21.341434     41.750000   -124.375000
75%      187.789307    194.870945    187.043140     35.601297     47.625000   -121.875000
max     1222.075684   1224.140625   1050.964844    185.897003     55.000000   -115.625000
#############################################################################
############## *I hope that is okay baby* - gale beggy ######################
#############################################################################
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
/glade/scratch/wchapman/Reforecast/models/NN_CRPS/F018/Reforecast_out/NN_CRPS_CNNPP_StartingYear2011_FINETUNEref2.pkl
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
